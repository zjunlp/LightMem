## 目标与产出

* 切回并运行“向量检索 + 记忆构建”，完成内存构建、向量入库、检索、问答与判题全流程。

* 产出：每个样本生成 `result_<question_id>.json`（默认写入 `../results`），并在本地 Qdrant 路径落盘集合数据。

## 前置条件验证

* Python 版本：优先使用 `Python 3.9`（已验证 Ark SDK 与依赖最稳定）。

* 网络：允许访问 HuggingFace（下载 LLMLingua-2 与 `sentence-transformers` 权重）。

* GPU：不要求；默认 CPU 运行（如有 CUDA 可后续调整）。

## 依赖安装

* 最小集合（已安装可跳过）：

  * `torch==2.8.0`

  * `transformers==4.57.0`

  * `sentence-transformers==2.6.1`

  * `qdrant-client==1.15.1`

  * `llmlingua==0.2.2`

  * `tiktoken==0.12.0`

  * `numpy>=2.0.2`

* 命令（如需补齐）：

  * `py -3.9 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch==2.8.0 transformers==4.57.0 sentence-transformers==2.6.1 qdrant-client==1.15.1 llmlingua==0.2.2 tiktoken==0.12.0 numpy==2.0.2`

## 脚本配置调整（文件与行）

* 入口脚本：`experiments/run_lightmem_qwen.py`

  * Ark 接入：`API_KEY`、`API_BASE_URL`（10-11）

  * 模型：`LLM_MODEL='deepseek-v3-1-250821'`，`JUDGE_MODEL='deepseek-r1-250528'`（12-13）

  * 模型路径（HF 名称，网络可用时自动下载）：

    * `LLMLINGUA_MODEL_PATH='microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank'`（16）

    * `EMBEDDING_MODEL_PATH='sentence-transformers/all-MiniLM-L6-v2'`（17）

  * 数据：将 `DATA_PATH` 改为你的“全量”数据 JSON（20）；目前为 `./data/longmemeval_s_min.json`，需替换成你的完整 LongMemEval 数据路径

  * 切回“向量检索 + 构建”配置：

    * `pre_compress=True`、`topic_segment=True`、`metadata_generate=True`（98-118）

    * `index_strategy='embedding'`、`retrieve_strategy='embedding'`（128, 136）

    * `text_embedder` 使用 HF 模型（128-135）

    * `embedding_retriever` 使用 Qdrant（136-145）：`collection_name=item['question_id']`、`embedding_model_dims=384`、`path=f'{QDRANT_DATA_DIR}/{collection_name}'`

  * 文件读取编码修复已完成（146）

* 兼容未知上下文窗：`src/lightmem/factory/memory_manager/openai.py:21` 使用 `get(..., 128000)` 避免 KeyError。

## 运行命令

* 从项目根目录执行：

  * `Set-Location e:\HuaweiMoveData\Users\92534\Desktop\论文gogogo\LightMem`

  * `$env:PYTHONPATH = (Join-Path $PWD 'src')`

  * `py -3.9 experiments\run_lightmem_qwen.py`

## 流程与验证（关键代码位置）

* 构建与抽取：`src/lightmem/memory/lightmem.py:186-349`（`add_memory` 主流程）

  * 元数据生成：`302-313` 调用 `OpenaiManager.meta_text_extract`

  * MemoryEntry 写入：`340-349`

* 向量入库：

  * 在线更新：`lightmem.py:368-394`（embedding 计算与 `self.embedding_retriever.insert(...)`）

  * 离线更新：`lightmem.py:409-436`（批量 upsert）

  * Qdrant 细节：`src/lightmem/factory/retriever/embeddingretriever/qdrant.py:52-83`（集合与落盘）、`146-153`（返回向量）

* 检索与问答：`experiments/run_lightmem_qwen.py:196-203` 组装检索上下文并调用 `llm.call`

* 判题：`experiments/run_lightmem_qwen.py:206-218`，结果保存：`227-230`

* 验证输出：检查 `e:\HuaweiMoveData\Users\92534\Desktop\论文gogogo\results\result_<question_id>.json`

## 性能与稳定性建议

* 设备：保持 `model_kwargs={'device':'cpu'}`（128-135）避免 CUDA 依赖。

* Qdrant 落盘：如数据很大，建议在 Qdrant 配置中开启 `on_disk=True`（对应 `VectorParams`，见 `qdrant.py:82`），我可在脚本中一并启用。

* 并行：`num_workers` 过高会增 RAM/显存峰值；先用 4–8。

## 变更点清单

* `experiments/run_lightmem_qwen.py`：

  * 更新 `DATA_PATH` 为你的全量数据路径（20）

  * 如需落盘优化：在 `embedding_retriever.configs` 增加 `on_disk=True`（136-145 附近）

<br />

